{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  EstimatedSalary  Male\n",
      "0     19            19000     1\n",
      "1     35            20000     1\n",
      "2     26            43000     0\n",
      "3     27            57000     0\n",
      "4     19            76000     1\n",
      "..   ...              ...   ...\n",
      "395   46            41000     0\n",
      "396   51            23000     1\n",
      "397   50            20000     0\n",
      "398   36            33000     1\n",
      "399   49            36000     0\n",
      "\n",
      "[400 rows x 3 columns]\n",
      "X shape =  (400, 4) \n",
      " y shape =  (400,)\n"
     ]
    }
   ],
   "source": [
    "#load data social network ads kaggle\n",
    "PATH = \"C:/Users/r.p/Downloads/\"\n",
    "data = pd.read_csv(PATH + 'datasets_7812_11044_Social_Network_Ads.csv')\n",
    "#print(data.head)\n",
    "Gender = pd.get_dummies(data['Gender'], drop_first= True)\n",
    "df = pd.concat([data, Gender], axis=1)\n",
    "\n",
    "# x,y = data.loc[:, ['Age', 'EstimatedSalary']].values,data.loc[:, 'Purchased'].values\n",
    "x = df.drop(['User ID', 'Gender', 'Purchased'], axis=1)\n",
    "y = df['Purchased']\n",
    "print(x)\n",
    "X = np.concatenate((np.ones((400,1)), x), axis = 1) #add column one\n",
    "print('X shape = ', X.shape ,'\\n', 'y shape = ', y.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialies weights ahd biases\n",
    "#w1 , w2 = np.random.randn()\n",
    "#b1, b2 = np.random.randn()\n",
    "#def h(x, w1 , b1):\n",
    "    #return w1*x + b1\n",
    "\n",
    "#forward     \n",
    "#h = w1*x + b1\n",
    "#def sigmoid(x):\n",
    "    #s=1/(1+np.exp(-x))\n",
    "    #return s\n",
    "#def scores(h, w2, b2):\n",
    "    #z = sigmoid(w2*h + b2)\n",
    "    #return z\n",
    "#def softmax()\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=1, keepdims=True)\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "#def loss_softmax()\n",
    "def softmax_loss(scores, y, mode='train'):\n",
    "    m = scores.shape[0]\n",
    "    probs = softmax(scores)\n",
    "    loss = -np.sum(np.log(probs[range(m), y])) / m\n",
    "    \n",
    "    if mode != 'train':\n",
    "        return loss\n",
    "    \n",
    "    backward\n",
    "    dscores = probs\n",
    "    dscores[range(m), y] -= 1.0\n",
    "    dscores /= m\n",
    "    \n",
    "    return loss, dscores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward\n",
    "#dscores\n",
    "\n",
    "#dh , dw2, db2 \n",
    "\n",
    "#dw1, db1\n",
    "\n",
    "\n",
    "\n",
    "#alpha = \n",
    "#epoche = 300\n",
    "#for i in range epoche:\n",
    "    #w1 := w1 -alpha*dw1\n",
    "    #w2 := w2 -alpha*dw2\n",
    "    #b1 := b1 -alpha*db1\n",
    "    #b2 := b2 -alpha*db2\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array([[1, 2, 3, 4],[5, 6, 7, 8]])\n",
    "#print(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def neural_net_loss(w, x, y, lmbda = 0.001, F = 4,H = 4, c= 1,mode = 'train'):\n",
    "    \n",
    "    #extract w1, w2, b1, b2 from w\n",
    "    w1 = np.reshape(w[: F*H], (F,H))\n",
    "    b1 = w[F*H: (F + 1) *H]\n",
    "    \n",
    "    w2 = np.reshape(w[(F + 1) * H: (F+ 1) * H + H * c], (H, c))\n",
    "    b2 = w[(F + 1) * H + H * c:]\n",
    "    \n",
    "    # Forward step\n",
    "    h_in = X @ w1 + b1\n",
    "    h = np.maximum(0, h_in)\n",
    "    scores = h @ w2 + b2\n",
    "    \n",
    "    \n",
    "    #compute loss\n",
    "    if mode != 'train':\n",
    "        return softmax_loss(scores, y, mode=mode)\n",
    "    \n",
    "    loss, dscores = softmax_loss(scores, y, mode= mode)\n",
    "    loss += 0.5 * lmbda * (np.sum(w1 ** 2) + np.sum(w2 ** 2))\n",
    "    \n",
    "    # backward step\n",
    "    db2 = dscores.sum(axis = 0)\n",
    "    dw2 = h.T @ dscores\n",
    "    dh = dscores @ w2.T\n",
    "    \n",
    "    dh[h_in < 0] = 0.0\n",
    "    db1 = dh.sum(axis=0)\n",
    "    dW1 = X.T @ dh\n",
    "    \n",
    "    dW1 += lmbda * W1\n",
    "    dW2 += lmbda * W2\n",
    "    \n",
    "    #concatenate all grads in a column vector\n",
    "    dw = np.concatenate((dw1.ravel(), db1, dw2.ravel(), db2), axis = 0)\n",
    "    \n",
    "    return loss, dw\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 4 # num. features\n",
    "H = 4 # num. hidden neurons\n",
    "c = 1 # num. classes\n",
    "\n",
    "w1 = np.random.randn(F, H)* 0.001  #????????\n",
    "w2 = np.random.randn(H, c)* 0.001  #????????\n",
    "\n",
    "b1 = np.zeros((H, )) \n",
    "b2 = np.zeros((c, ))\n",
    "\n",
    "# concatenate all parameters in one column vector\n",
    "w = np.concatenate((w1.ravel(), b1, w2.ravel(), b2))\n",
    "\n",
    "\n",
    "result = minimize(\n",
    "     neural_net_loss,\n",
    "     x0 = w,\n",
    "     args = (X, y),\n",
    "     method = 'CG',\n",
    "     jac = True,\n",
    "     options = {'maxiter': 50},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
